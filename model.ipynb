{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":65711,"databundleVersionId":7405009,"sourceType":"competition"}],"dockerImageVersionId":30626,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Load dataset\nimport pandas as pd \nimport numpy as np\n\nTrain_set = pd.read_csv('/kaggle/input/playground-series-s4e1/train.csv')\nprint(Train_set.head())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-06T12:25:50.857405Z","iopub.execute_input":"2024-01-06T12:25:50.858539Z","iopub.status.idle":"2024-01-06T12:25:51.722889Z","shell.execute_reply.started":"2024-01-06T12:25:50.858489Z","shell.execute_reply":"2024-01-06T12:25:51.721642Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"   id  CustomerId         Surname  CreditScore Geography Gender   Age  Tenure  \\\n0   0    15674932  Okwudilichukwu          668    France   Male  33.0       3   \n1   1    15749177   Okwudiliolisa          627    France   Male  33.0       1   \n2   2    15694510           Hsueh          678    France   Male  40.0      10   \n3   3    15741417             Kao          581    France   Male  34.0       2   \n4   4    15766172       Chiemenam          716     Spain   Male  33.0       5   \n\n     Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n0       0.00              2        1.0             0.0        181449.97   \n1       0.00              2        1.0             1.0         49503.50   \n2       0.00              2        1.0             0.0        184866.69   \n3  148882.54              1        1.0             1.0         84560.88   \n4       0.00              2        1.0             1.0         15068.83   \n\n   Exited  \n0       0  \n1       0  \n2       0  \n3       0  \n4       0  \n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, StandardScaler\n\n# 1. Remove rows with missing values in any column\nTrain_set = Train_set.dropna()\n\n# Label encoding the categorical features\ncategorical_features = [\"Surname\", \"Geography\", \"Gender\"]\nlabel_encoder_X = LabelEncoder()\n\nfor feature in categorical_features:\n    Train_set[feature] = label_encoder_X.fit_transform(Train_set[feature])\n\n# Scaling numerical features\nnumerical_features = [\"CreditScore\", \"Age\", \"Tenure\", \"Balance\", \"NumOfProducts\", \"EstimatedSalary\"]\nscaler = StandardScaler()\n\nfor feature in numerical_features:\n    Train_set[feature] = scaler.fit_transform(Train_set[feature].values.reshape(-1, 1))\n\nTrain_set.drop([\"id\", \"CustomerId\"], axis=1, inplace=True)\n\nprint(Train_set.head())","metadata":{"execution":{"iopub.status.busy":"2024-01-06T12:25:51.725579Z","iopub.execute_input":"2024-01-06T12:25:51.726048Z","iopub.status.idle":"2024-01-06T12:25:52.497592Z","shell.execute_reply.started":"2024-01-06T12:25:51.726001Z","shell.execute_reply":"2024-01-06T12:25:52.496441Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"   Surname  CreditScore  Geography  Gender       Age    Tenure   Balance  \\\n0     1924     0.144135          0       1 -0.578074 -0.719973 -0.883163   \n1     1925    -0.367706          0       1 -0.578074 -1.432694 -0.883163   \n2     1178     0.268974          0       1  0.211354  1.774548 -0.883163   \n3     1299    -0.941966          0       1 -0.465299 -1.076334  1.486918   \n4      467     0.743362          2       1 -0.578074 -0.007253 -0.883163   \n\n   NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n0       0.814298        1.0             0.0         1.369486       0  \n1       0.814298        1.0             1.0        -1.254085       0  \n2       0.814298        1.0             0.0         1.437422       0  \n3      -1.013348        1.0             1.0        -0.557018       0  \n4       0.814298        1.0             1.0        -1.938770       0  \n","output_type":"stream"}]},{"cell_type":"code","source":"# 2. Split dataset into training and validation sets\nfrom sklearn.model_selection import train_test_split\n\nX = Train_set.drop([\"Exited\"], axis=1).values\ny = Train_set[\"Exited\"].values\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n\nprint(\"X_train shape: \", X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T12:25:52.499000Z","iopub.execute_input":"2024-01-06T12:25:52.499363Z","iopub.status.idle":"2024-01-06T12:25:52.656036Z","shell.execute_reply.started":"2024-01-06T12:25:52.499313Z","shell.execute_reply":"2024-01-06T12:25:52.654897Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"X_train shape:  (132027, 11)\n","output_type":"stream"}]},{"cell_type":"code","source":"# create dataloader\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n\nbatch_size = 32\n\ntrain_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\nval_data = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n\ntrain_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\nval_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size)\n\nval_loader_iter = iter(val_loader)\ndata, label = next(val_loader_iter)\nprint(data[1])","metadata":{"execution":{"iopub.status.busy":"2024-01-06T13:48:55.580494Z","iopub.execute_input":"2024-01-06T13:48:55.580930Z","iopub.status.idle":"2024-01-06T13:48:55.597158Z","shell.execute_reply.started":"2024-01-06T13:48:55.580895Z","shell.execute_reply":"2024-01-06T13:48:55.595466Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"tensor([ 1.2990e+03,  6.6846e-01,  0.0000e+00,  1.0000e+00, -4.6530e-01,\n        -1.0763e+00, -8.8316e-01,  8.1430e-01,  1.0000e+00,  1.0000e+00,\n         9.7180e-01], dtype=torch.float64)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Build the model\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass FeedForward(nn.Module):\n    def __init__(self, num_hidden):\n        super(FeedForward, self).__init__()\n        self.num_hidden = num_hidden\n        \n        self.net = nn.Sequential(\n            nn.Linear(self.num_hidden, self.num_hidden),\n            nn.ReLU(),\n        )\n    \n    def forward(self, x):\n        return self.net(x)\n    \nclass Net(nn.Module):\n    def __init__(self, input_size, hidden_layers, hidden_size, output_size):\n        super(Net, self).__init__()\n        self.input_size = input_size\n        self.hidden_layers = hidden_layers\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n\n        self.fc1 = nn.Linear(self.input_size, self.hidden_size)\n        self.blocks = nn.ModuleList([FeedForward(self.hidden_size) for _ in range(self.hidden_layers)])\n        self.fc2 = nn.Linear(self.hidden_size, self.output_size)\n        self.sigmoid = nn.Sigmoid()\n    \n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        for block in self.blocks:\n            x = block(x)\n        x = self.fc2(x)\n        x = self.sigmoid(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-01-06T12:25:55.783918Z","iopub.execute_input":"2024-01-06T12:25:55.784406Z","iopub.status.idle":"2024-01-06T12:25:55.796010Z","shell.execute_reply.started":"2024-01-06T12:25:55.784374Z","shell.execute_reply":"2024-01-06T12:25:55.794748Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Defining hyperparameters\ninput_size = X_train.shape[1]\nhidden_layers = 3\nhidden_size = 64\noutput_size = 1\nalpha = 1e-3\nepochs = 200\n\n# Initialize the model\nmodel = Net(input_size, hidden_layers, hidden_size, output_size)\n\n# Define the loss function and optimizer\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=alpha)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T12:25:55.797577Z","iopub.execute_input":"2024-01-06T12:25:55.798018Z","iopub.status.idle":"2024-01-06T12:25:55.840220Z","shell.execute_reply.started":"2024-01-06T12:25:55.797986Z","shell.execute_reply":"2024-01-06T12:25:55.838990Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Train the model\n\nfor epoch in range(epochs):\n    train_loss = 0.0\n\n    model.train()\n    \n    for data, target in train_loader:\n        optimizer.zero_grad()\n        output = model.forward(data.float())\n        loss = criterion(output.squeeze(), target.float())\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()*data.size(0)\n\n    train_loss = train_loss/len(train_loader.dataset)\n\n    if epoch % 10 == 0:\n        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))","metadata":{"execution":{"iopub.status.busy":"2024-01-06T12:25:55.841629Z","iopub.execute_input":"2024-01-06T12:25:55.841978Z","iopub.status.idle":"2024-01-06T12:56:08.288745Z","shell.execute_reply.started":"2024-01-06T12:25:55.841949Z","shell.execute_reply":"2024-01-06T12:56:08.287743Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch: 1 \tTraining Loss: 0.525553\nEpoch: 11 \tTraining Loss: 0.517186\nEpoch: 21 \tTraining Loss: 0.516045\nEpoch: 31 \tTraining Loss: 0.516529\nEpoch: 41 \tTraining Loss: 0.515252\nEpoch: 51 \tTraining Loss: 0.480728\nEpoch: 61 \tTraining Loss: 0.355956\nEpoch: 71 \tTraining Loss: 0.350045\nEpoch: 81 \tTraining Loss: 0.345312\nEpoch: 91 \tTraining Loss: 0.340246\nEpoch: 101 \tTraining Loss: 0.337265\nEpoch: 111 \tTraining Loss: 0.334171\nEpoch: 121 \tTraining Loss: 0.332686\nEpoch: 131 \tTraining Loss: 0.332113\nEpoch: 141 \tTraining Loss: 0.330289\nEpoch: 151 \tTraining Loss: 0.329825\nEpoch: 161 \tTraining Loss: 0.328108\nEpoch: 171 \tTraining Loss: 0.327675\nEpoch: 181 \tTraining Loss: 0.327421\nEpoch: 191 \tTraining Loss: 0.325939\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"churn_model_weights.pt\")","metadata":{"execution":{"iopub.status.busy":"2024-01-06T13:24:20.670677Z","iopub.execute_input":"2024-01-06T13:24:20.671066Z","iopub.status.idle":"2024-01-06T13:24:20.679491Z","shell.execute_reply.started":"2024-01-06T13:24:20.671034Z","shell.execute_reply":"2024-01-06T13:24:20.677285Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model.eval()\ncorrect = 0\ntotal_samples = 0\n\nwith torch.no_grad():\n    for data, label in val_loader:\n        # Forward pass\n        output = model(data.float())\n        \n        # Threshold the output and convert to the same type as target\n        pred = (output > 0.5).float()\n\n        # Update correct count\n        correct += (pred == label.view_as(pred)).sum().item()\n        \n        # Update total samples count\n        total_samples += data.size(0)\n\n# Calculate accuracy\naccuracy = correct / total_samples * 100.0\nprint(f'Validation Accuracy: {accuracy:.4f}%')","metadata":{"execution":{"iopub.status.busy":"2024-01-06T13:57:16.545396Z","iopub.execute_input":"2024-01-06T13:57:16.545781Z","iopub.status.idle":"2024-01-06T13:57:17.129923Z","shell.execute_reply.started":"2024-01-06T13:57:16.545751Z","shell.execute_reply":"2024-01-06T13:57:17.128711Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Validation Accuracy: 85.4910%\n","output_type":"stream"}]},{"cell_type":"code","source":"Test_set = pd.read_csv(\"/kaggle/input/playground-series-s4e1/test.csv\")\n\n# Test set preprocessing\n\nTest_set = Test_set.dropna()\nprint(len(Test_set))\n# Label encoding the categorical features\ncategorical_features = [\"Surname\", \"Geography\", \"Gender\"]\nlabel_encoder_X = LabelEncoder()\n\nfor feature in categorical_features:\n    Test_set[feature] = label_encoder_X.fit_transform(Test_set[feature])\n\n# Scaling numerical features\nnumerical_features = [\"CreditScore\", \"Age\", \"Tenure\", \"Balance\", \"NumOfProducts\", \"EstimatedSalary\"]\nscaler = StandardScaler()\n\nfor feature in numerical_features:\n    Test_set[feature] = scaler.fit_transform(Test_set[feature].values.reshape(-1, 1))\n    \nTest_set = Test_set.drop([\"CustomerId\"], axis=1)\nTest_ids = Test_set[\"id\"]\nTest_set = Test_set.drop([\"id\"], axis=1)\nprint(Test_set.head())\n\n\n# create dataloader\ntest_X = Test_set\ntest_X = test_X.values\n\ntest_X = TensorDataset(torch.from_numpy(test_X))\ntest_loader = DataLoader(test_X, shuffle=False, batch_size=batch_size)\nprint(len(test_loader))","metadata":{"execution":{"iopub.status.busy":"2024-01-06T14:55:29.893710Z","iopub.execute_input":"2024-01-06T14:55:29.894646Z","iopub.status.idle":"2024-01-06T14:55:30.191003Z","shell.execute_reply.started":"2024-01-06T14:55:29.894602Z","shell.execute_reply":"2024-01-06T14:55:30.189430Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"110023\n   Surname  CreditScore  Geography  Gender       Age    Tenure   Balance  \\\n0     1482    -0.878176          0       0 -1.706504 -1.067887 -0.881274   \n1     1812     0.329567          0       0  0.888990 -1.067887 -0.881274   \n2     1246    -0.006609          0       0 -0.465181  0.713922 -0.881274   \n3     1832     0.304665          0       1 -0.239486  1.070284 -0.881274   \n4     1079     1.188684          1       1 -0.013791  1.783008  1.050038   \n\n   NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \n0       0.820030        0.0             1.0         0.967874  \n1      -1.015806        1.0             0.0        -0.790939  \n2       0.820030        1.0             0.0         0.528413  \n3      -1.015806        1.0             0.0         0.032150  \n4      -1.015806        1.0             0.0         0.539331  \n3439\ntest_ids shape:  110023\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions = []\nmodel.eval()\n\nwith torch.no_grad():\n    for data in test_loader:\n        outputs = model.forward(data[0].float())\n        predictions.extend(outputs.squeeze().tolist())\n\nprint(len(predictions))","metadata":{"execution":{"iopub.status.busy":"2024-01-06T15:01:50.523575Z","iopub.execute_input":"2024-01-06T15:01:50.523962Z","iopub.status.idle":"2024-01-06T15:01:51.863251Z","shell.execute_reply.started":"2024-01-06T15:01:50.523931Z","shell.execute_reply":"2024-01-06T15:01:51.862495Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"110023\n165035\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n\ndf = pd.DataFrame({\"id\": Test_ids, \"Exited\": predictions})\n\n# Save to CSV\ndf.to_csv(\"predictions.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T15:02:10.198738Z","iopub.execute_input":"2024-01-06T15:02:10.199104Z","iopub.status.idle":"2024-01-06T15:02:10.539913Z","shell.execute_reply.started":"2024-01-06T15:02:10.199075Z","shell.execute_reply":"2024-01-06T15:02:10.538947Z"},"trusted":true},"execution_count":68,"outputs":[]}]}